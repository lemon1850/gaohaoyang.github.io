---
layout: post
title: hadoop分布式搭建
categories: 大数据
tags:  大数据 hadoop spark yarn hdfs
---

* content
{:toc}

> 我的技术博客，主要是记载看过的书以及对写的好的博客文章的搬运整理，方便自己他人查看，也方便别人指出我文章中的错误，达到一起学习的目的。
> 技术永无止境

本文主要是对hadoop分布式平台搭建



## 安装virtualbox和ubuntu16.04

其中配置两张网卡

一张配置为桥接网络，一张配置为NAT网络
![](media/15147996219589/15147996607534.jpg)

![](media/15147996219589/15147996728270.jpg)

从而是虚拟机之间相互访问，主机跟虚拟机之间相互访问。

安装操作系统过程中，可以设置hostname(master/slave)，或者后面通过修改配置文件/etc/hosts

![](media/15147996219589/15147998262875.jpg)

然后我设置用户名密码 tianhe/xxxxx

登陆系统后，配置root用户名密码
`sudo passwd root`

### ssh配置

先下载`apt-get install ssh`
然后配置`etc/ssh/sshd_config`，修改`PermitRootLogin=yes`，然后`service ssh restart`

修改host文件`vim /etc/host`
加入下面配置

```conf
10.12.39.86 master
10.12.39.239 slaver
```

接着配置免密登陆, 登陆Master机器，创建密钥，回车之后，会在/root/.ssh/目录生成id_rsa和id_rsa.pub

```shell
ssh-keygen -t rsa
```
然后复制公钥id_rsa.pub并加入到authorized_keys

```shell
cat id_rsa.pub >> authorized_keys
```

或者通过`ssh-copy-id -i /root/.ssh/id_rsa.pub remoteServer`  复制公钥到远程服务器

## 配置运行环境

把下载好的

* jdk-8u152-linux-x64.tar.gz
* scala-2.12.4.tgz
* hadoop-2.8.3.tar.gz
* spark-2.2.1-bin-hadoop2.7.tgz

通过ftp拷贝到master的/opt/目录并解压

配置环境变量

```shell
vi /etc/profile
```


```shell
export JAVA_HOME=/opt/jdk1.8.0_152
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export SCALA_HOME=/opt/scala-2.12.4
export HADOOP_HOME=/opt/hadoop-2.8.3
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$SCALA_HOME/bin:$HADOOP_HOME/bin:$PATH
```

然后刷新配置`source /etc/profile`

验证安装成功

```shell
jave -version
scala -version
hadoop version
```

## hadoop 配置

创建目录

```
/root
    /hadoop
    /dfs
        /name
        /data
```

### 配置core-site.xml


```xml
<configuration>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/root/hadoop/tmp</value>
                <description>Abase for other temporary directories.</description>
        </property>

        <property>
                <name>fs.defaultFS</name>
                <value>hdfs://master:9000</value>
        </property>

        <property>
                <name>io.file.buffer.size</name>
                <value>4096</value>
        </property>
</configuration>
```


### 配置hdfs-site.xml


```xml
<configuration>
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>master:9001</value>
        </property>

        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/root/hadoop/dfs/name</value>
        </property>

        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/root/hadoop/dfs/data</value>
        </property>

        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>

        <property>
                <name>dfs.webhdfs.enabled</name>
                <value>true</value>
        </property>
</configuration>
```

### 配置mapred-site.xml


```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
                <final>true</final>
        </property>

        <property>
                <name>mapreduce.jobtracker.http.address</name>
                <value>master:50030</value>
        </property>

        <property>
                <name>mapreduce.jobhistory.address</name>
                <value>master:10020</value>
        </property>

        <property>
                <name>mapreduce.jobhistory.webapp.address</name>
                <value>master:19888</value>
        </property>

        <property>
                <name>mapred.job.tracker</name>
                <value>http://master:9001</value>
        </property>
</configuration>
```

### 配置yarn-site.xml


```xml
<configuration>
        <property>
                <name>yarn.resourcemanager.hostname</name>
                <value>master</value>
        </property>

        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>

        <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>

        <property>
                <name>yarn.resourcemanager.address</name>
                <value>master:8032</value>
        </property>

        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>master:8030</value>
        </property>

        <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>master:8035</value>
        </property>

        <property>
                <name>yarn.resourcemanager.admin.address</name>
                <value>master:8033</value>
        </property>

        <property>
                <name>yarn.resourcemanager.webapp.address</name>
                <value>master:8088</value>
        </property>
</configuration>
```

### 配置slaves


```xml
master
slaver
```

### 将上述配置复制一份到从节点相应目录

slaver节点也创建相应目录

```
/root
    /hadoop
    /dfs
        /name
        /data
```

`scp -r /opt/hadoop-2.8.3 slaver://opt/`

### 格式化NameNode

`hadoop namenode -format`


### master节点启动Hadoop集群

`sbin/start-all.sh`

然后通过http://master:50070查看HDFS, 通过http://master:8088查看YARN


## Spark集群安装

`tar -xzvf spark-2.2.tgz`

更新`/etc/profile`

```shell
export JAVA_HOME=/opt/jdk1.8.0_152
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH
export SCALA_HOME=/opt/scala-2.12.4
export HADOOP_HOME=/opt/hadoop-2.8.3
export HIVE_HOME=/opt/hive-2.2
export SPARK_HOME=/opt/spark-2.2
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$SCALA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$SPARK_HOME/bin:$PATH
```


修改conf/spark-env.sh


```shell
export JAVA_HOME=/opt/jdk1.8.0_152
export SCALA_HOME=/opt/scala-2.12.4
export HADOOP_CONF_DIR=/opt/hadoop-2.8.3/etc/hadoop
export SPARK_WORKER_MEMORY=512m
export SPARK_MASTER_IP=10.12.39.86
```

SPARK_MASTER_IP 指定 Spark 集群 Master 节点的 IP 地址； 
SPARK_WORKER_MEMORY 指定的是 Worker 节点能够分配给 Executors 的最大内存大小； 
HADOOP_CONF_DIR 指定 Hadoop 集群配置文件目录。

修改conf/slaves
编辑内容

```conf
master
slaver
```

上诉文件复制到从节点

```shell
scp -r spark-2.2 slaver://opt/
```

启动Spark集群

`sbin/start-all.sh`

启动成功后，访问http://master:8080/

运行spark-shell实例

`bin/spark-shell`

## 问题记录
[网络连接错误](https://wiki.apache.org/hadoop/ConnectionRefused)
目录部分存取数据出错，需要重新格式化

## 主要参考

[伪分布搭建](http://hadoop.apache.org/docs/r2.8.3/hadoop-project-dist/hadoop-common/ClusterSetup.html)
[hadoop和spark集群搭建](http://blog.csdn.net/upshi/article/details/61620417)


